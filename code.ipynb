{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import pdfplumber\n",
    "import fitz  \n",
    "import re\n",
    "import textwrap\n",
    "import os\n",
    "import numpy as np\n",
    "# set device to CUDA if available\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('API_KEY')` to fetch an environment variable.\n",
    "API_KEY=\"AIzaSyCzcopOrcDHgZIdjrFuOrYeBasjG0qiwec\" #fine grained token\n",
    "\n",
    "genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_mupdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = []\n",
    "    \n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        # Get the page's text and maintain layout by specifying 'text' option\n",
    "        text = page.get_text(\"text\")\n",
    "        full_text.append(text)\n",
    "\n",
    "    # Join all text into a corpus\n",
    "    corpus = \"\\n\".join(full_text)\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Provide your file path here\n",
    "# pdf_path = 'iesc111.pdf'\n",
    "# corpus = extract_text_from_pdf_mupdf(pdf_path)\n",
    "\n",
    "# # write the extracted text to a text file\n",
    "# with open('extracted_text_mupdf.txt', 'w') as f:\n",
    "#     f.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the extracted text into a pandas dataframe\n",
    "#read from the text file\n",
    "corpus = open('extracted_text_mupdf.txt', 'r').read()\n",
    "#split the text into lines using the newline character .? \n",
    "corpus = corpus.replace('\\n', ' ')\n",
    "corpus = corpus.replace('Rationalised 2023-24', ' ')\n",
    "sentence_boundary = re.compile(r\"\"\"\n",
    "        (?<!\\d)\\.        # Match a period that is not preceded by a digit (avoid decimals)\n",
    "        (?<!\\.\\d)        # Avoid cases like 1.5 cm\n",
    "        (?<![A-Za-z]\\.[A-Za-z])  # Avoid cases like abbreviations e.g. A.B.\n",
    "        (?<!\\d\\.\\d)      # Avoid decimal numbers\n",
    "        |                # OR\n",
    "        \\?               # Match a question mark (?)\n",
    "        \"\"\", re.VERBOSE)\n",
    "\n",
    "    # Split the text based on the pattern\n",
    "sentences = sentence_boundary.split(corpus)\n",
    "# Clean up leading and trailing spaces\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 approaches  \n",
    "- #### 1 split sentence with total_char/num_docs chars each\n",
    "- #### 2. split documents based on sematic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_sentences_into_documents(sentences, num_docs):\n",
    "    total_chars = sum(len(sentence) for sentence in sentences)\n",
    "    \n",
    "    target_size = total_chars // num_docs\n",
    "    \n",
    "    documents = []\n",
    "    current_doc = []\n",
    "    current_doc_size = 0\n",
    "    \n",
    "    # Iterate through sentences and group them into documents\n",
    "    for sentence in sentences:\n",
    "        sentence_len = len(sentence)\n",
    "        \n",
    "        # If adding the sentence exceeds the target size, start a new document\n",
    "        if current_doc_size + sentence_len > target_size and len(documents) < num_docs - 1:\n",
    "            documents.append(' '.join(current_doc))\n",
    "            current_doc = []\n",
    "            current_doc_size = 0\n",
    "        \n",
    "        current_doc.append(sentence)\n",
    "        current_doc_size += sentence_len\n",
    "    \n",
    "    # Add the last document\n",
    "    if current_doc:\n",
    "        documents.append(' '.join(current_doc))\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_method1 = divide_sentences_into_documents(sentences, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyash/Desktop/IIIT/Sarvam/myenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model for generating embeddings\n",
    "encoding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Chunking function using sliding window strategy\n",
    "def chunk_documents(documents, window_size=256, overlap=16):\n",
    "    chunks = []\n",
    "    for doc in documents:\n",
    "        words = doc.split()\n",
    "        for i in range(0, len(words), window_size - overlap):\n",
    "            chunk = ' '.join(words[i:i + window_size])\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# Function to create and store FAISS index\n",
    "def create_faiss_index(chunks, index_save_path='index.faiss', json_save_path='memory.json'):\n",
    "    # Convert chunks to embeddings\n",
    "    chunk_embeddings = encoding_model.encode(chunks)\n",
    "    chunk_embeddings = np.array(chunk_embeddings).astype('float32')\n",
    "    \n",
    "    # Initialize FAISS index\n",
    "    dimension = chunk_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)  # Using L2 distance metric\n",
    "\n",
    "    # Add embeddings to the index\n",
    "    index.add(chunk_embeddings)\n",
    "    \n",
    "    # Save FAISS index in binary format\n",
    "    faiss.write_index(index, index_save_path)\n",
    "\n",
    "    # Save chunks in memory.json\n",
    "    memory = {\n",
    "        \"chunks\": chunks\n",
    "    }\n",
    "    \n",
    "    with open(json_save_path, 'w') as f:\n",
    "        json.dump(memory, f)\n",
    "\n",
    "# Function to load the FAISS index and chunks from disk\n",
    "def load_faiss_index(index_save_path='index.faiss', json_save_path='memory.json'):\n",
    "    # Load FAISS index\n",
    "    index = faiss.read_index(index_save_path)\n",
    "\n",
    "    # Load chunks\n",
    "    with open(json_save_path, 'r') as f:\n",
    "        memory = json.load(f)\n",
    "    chunks = memory[\"chunks\"]\n",
    "    \n",
    "    return index, chunks\n",
    "\n",
    "# Function to retrieve the top k documents for a query\n",
    "def retrieve_top_k_documents(query, k=3, index_save_path='index.faiss', json_save_path='memory.json'):\n",
    "    # Load the FAISS index and chunks from disk\n",
    "    index, chunks = load_faiss_index(index_save_path, json_save_path)\n",
    "\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = encoding_model.encode([query]).astype('float32')\n",
    "\n",
    "    # Search the index for top k documents\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Return the top k chunks and their scores\n",
    "    top_chunks = [(chunks[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
    "    return top_chunks\n",
    "\n",
    "\n",
    "# documents= documents_method1\n",
    "\n",
    "# # Chunk the documents using the sliding window strategy\n",
    "# chunks = chunk_documents(documents)\n",
    "# # Create and store the FAISS index and chunks\n",
    "# create_faiss_index(chunks)\n",
    "# Example query\n",
    "# the above function is only needed to be run once to create the index and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 11.1 Production of Sound Activity _____________11.1 • Take a tuning fork and set it vibrating by striking its prong on a rubber pad Bring it near your ear • Do you hear any sound • Touch one of the prongs of the vibrating tuning fork with your finger and share your experience with your friends • Now, suspend a table tennis ball or a small plastic ball by a thread from a support [Take a big needle and a thread, put a knot at one end of the thread, and then with the help of the needle pass the thread through the ball] Touch the ball gently with the prong of a vibrating tuning fork (Fig 11.1) • Observe what happens and discuss with your friends Activity _____________11.2 • Fill water in a beaker or a glass up to the brim, Score: 1.7397418022155762\n",
      "Document: 11.3.2 REVERBERATION A sound created in a big hall will persist by repeated reflection from the walls until it is reduced to a value where it is no longer audible The repeated reflection that results in this persistence of sound is called reverberation In an auditorium or big hall excessive reverberation is highly undesirable To reduce reverberation, the roof and walls of the auditorium are generally covered with sound-absorbent materials like compressed fibreboard, rough plaster or draperies The seat materials are also selected on the basis of their sound absorbing properties Example 11.2 A person clapped his hands near a cliff and heard the echo after 2 s What is the distance of the cliff from the person if the speed of the sound, v is taken as 346 m s–1, Score: 1.7904090881347656\n",
      "Document: Solution: Given, Frequency, ν = 2 kHz = 2000 Hz Wavelength, λ = 35 cm = 0.35 m We know that speed, v of the wave = wavelength × frequency v = λ ν = 0.35 m 2000 Hz = 700 m/s The time taken by the wave to travel a distance, d of 1.5 km is Thus sound will take 2.1 s to travel a distance of 1.5 km uestions 1. What are wavelength, frequency, time period and amplitude of a sound wave 2. How are the wavelength and frequency of a sound wave related to its speed 3. Calculate the wavelength of a sound wave whose frequency is 220 Hz and speed is 440 m/s in a given medium 4. A person is listening to a tone of 500 Hz sitting at a distance of 450 m from the source of the sound What is the time interval between successive compressions from the source, Score: 1.801283597946167\n"
     ]
    }
   ],
   "source": [
    "query = \"hi\"\n",
    "\n",
    "# Retrieve top 3 documents and their scores\n",
    "top_documents = retrieve_top_k_documents(query, k=3)\n",
    "\n",
    "for doc, score in top_documents:\n",
    "    print(f\"Document: {doc}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query):\n",
    "    results = retrieve_top_k_documents(query, k=3)\n",
    "    \n",
    "    if results[0][1]<1.5:\n",
    "\n",
    "        prompt = (\"\"\"SYSTEM:\n",
    "\n",
    "    You are a friendly, knowledgeable, and enthusiastic high school teacher. Your goal is to help students with their academic queries across various subjects. As a teacher, you should explain concepts clearly and patiently, always offering encouragement and support. Use examples and analogies whenever possible to help students understand complex topics. If the student seems confused, clarify your explanation, but avoid overwhelming them with too much information at once.\n",
    "\n",
    "    Make sure to maintain a positive and motivating tone, encouraging curiosity and a love for learning. If you're unsure of the answer, reassure the student that it's okay not to know everything right away and guide them on how to explore the topic further.\n",
    "\n",
    "    You should base your response on the provided context and documents retrieved by the system, answering the student’s question with accurate and relevant information.\n",
    "\n",
    "    You are a teacher who should provide a helpful and educational response to the student's query. Ensure your answer is concise, informative, and tailored to the student's academic level.\n",
    "\n",
    "   USER:                 \n",
    "\n",
    "    Use the following context to answer the student's query:\n",
    "\n",
    "    QUESTION: '{query}'\n",
    "\n",
    "    PASSAGES: \n",
    "    1. {relevant_passage_1}\n",
    "    2. {relevant_passage_2}\n",
    "    3. {relevant_passage_3}\n",
    "\n",
    "    ASSISTANT:\n",
    "\n",
    "    ANSWER:\n",
    "\n",
    "    \n",
    "    \"\"\").format(query=query, relevant_passage_1=results[0][0], relevant_passage_2=results[1][0], relevant_passage_3=results[2][0])\n",
    "    else:\n",
    "        prompt = textwrap.dedent(\"\"\"SYSTEM:\n",
    "\n",
    "You are a friendly, knowledgeable, and enthusiastic high school teacher. Your goal is to help students with their academic queries across various subjects, even when no specific documents are provided. As a teacher, you should explain concepts clearly and patiently, always offering encouragement and support. Use examples and analogies to simplify complex topics, and provide guidance on how students can further explore or understand the material.\n",
    "\n",
    "If the student asks a question that doesn't match the available information, reassure them that it's okay to ask about different topics and answer based on your own expertise. Be sure to maintain a positive and motivating tone, and encourage the student to stay curious and engaged.\n",
    "\n",
    "Your response should be concise, informative, and tailored to the student's academic level.\n",
    "\n",
    "USER:                    \n",
    "\n",
    "QUESTION: '{query}'\n",
    "\n",
    "ASSISTATNT:\n",
    "\n",
    "ANSWER:\n",
    "\n",
    "\n",
    "\"\"\").format(query=query)\n",
    "                  \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SCIENCE 130 Heinrich Rudolph Hertz was born on 22 February 1857 in Hamburg, Germany and educated at the University of Berlin He confirmed J C Maxwell’s electromagnetic theory by his experiments He laid the foundation for future development of radio, telephone, telegraph and even television He also discovered the photoelectric effect which was later explained by Albert Einstein The SI unit of frequency was named as hertz in his honour Fig 11.6(b) represent the density and pressure variations, respectively, as a sound wave propagates in the medium Compressions are the regions where particles are crowded together and represented by the upper portion of the curve in Fig 11.6(c) The peak represents the region of maximum compression',\n",
       "  1.5368121),\n",
       " ('SCIENCE 136 squeaks of the bat and know when a bat is flying nearby, and are able to escape capture Rats also play games by producing ultrasound Hearing Aid: People with hearing loss may need a hearing aid A hearing aid is an electronic, battery operated device The hearing aid receives sound through a microphone The microphone converts the sound waves to electrical signals These electrical signals are amplified by an amplifier The amplified electrical signals are given to a speaker of the hearing aid The speaker converts the amplified electrical signal to sound and sends to the ear for clear hearing in construction of big structures like buildings, bridges, machines and also scientific equipment',\n",
       "  1.5430448),\n",
       " ('The hearing aid receives sound through a microphone The microphone converts the sound waves to electrical signals These electrical signals are amplified by an amplifier The amplified electrical signals are given to a speaker of the hearing aid The speaker converts the amplified electrical signal to sound and sends to the ear for clear hearing in construction of big structures like buildings, bridges, machines and also scientific equipment The cracks or holes inside the metal blocks, which are invisible from outside reduces the strength of the structure Ultrasonic waves are allowed to pass through the metal block and detectors are used to detect the transmitted waves If there is even a small defect, the ultrasound gets reflected back indicating the presence of the flaw or defect, as shown in Fig',\n",
       "  1.568424)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_prompt(\"how is\")  \n",
    "query = \"why is science important\"  \n",
    "results = retrieve_top_k_documents(query, k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-1.5-flash-002\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash-001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer_to_markdown_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in model.generate_content(make_prompt(query), stream=True):\n",
    "            f.write(line.text + '\\n')\n",
    "            f.flush()\n",
    "\n",
    "write_answer_to_markdown_file('answer.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi there! 👋  It's great to see you're ready to learn!  What can I help you with today?  Don't be shy, I'm here to help you with any questions you have, no matter how big or small.  😊 \\n\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = model.generate_content(make_prompt(query))\n",
    "answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=False,\n",
       "    iterator=<_StreamingResponseIterator>,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"That's a\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 651,\n",
       "        \"candidates_token_count\": 4,\n",
       "        \"total_token_count\": 655\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suyash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
